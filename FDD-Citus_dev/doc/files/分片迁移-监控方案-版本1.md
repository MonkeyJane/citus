# 一、背景

为实现在线分片迁移功能，需提供有效的分片迁移监控手段。支撑程序高度自动化的同时，向用户实时呈现分片迁移进度、状态，并尽快地识别迁移过程中的异常，来支持程序进行自动化处理或者通知用户手动处理。

# 二、需求

我们基于PG逻辑复制机制，实现分片迁移功能。在分片源节点创建发布者来发布该分片，在目的节点创建该发布者的订阅者，即可完成分片数据的迁移。

分片迁移状态：PG原生 `pg_subscription_rel` 表中已提供属性`srsubstate`来展现订阅表的逻辑复制状态，该属性可用于分片迁移状态。因此对分片迁移状态的实现不作分析。

分片迁移进度：通过SQL实时在目的节点查询该分片大小呈现，具体SQL方案暂未确定，暂不讨论。

分片迁移异常可重入：需将异常场景相关数据保存到数据库中，进行处理。本方案中暂不讨论。

分片迁移异常：可能导致迁移失败、甚至是恢复后的重入操作。本方案将针对异常场景及场景的识别区分，进行重点分析。

涉及以下5个异常场景：（网络故障场景暂未模拟）

1. 订阅端某订阅表（1个或多个）逻辑复制冲突
2. 订阅端PG进程异常 / 网络故障
3. 订阅端某逻辑复制进程（1个或多个）异常
4. 发布端PG进程异常 / 网络故障
5. 发布端某逻辑复制进程（1个或多个）异常

# 三、场景分析

逻辑复制过程中，通过抓取发布端、订阅端日志记录，并在两端定时执行SQL抓取相关表数据，来分析异常场景。

```sql
## 发布端
select * from pg_publication_rel;
select * from pg_stat_replication;
select * from pg_replication_slots;
select * from pg_publication_tables;

## 订阅端
select * from pg_subscription;
select * from pg_subscription_rel;
select * from pg_stat_subscription;
select * from pg_replication_origin_status;
```

## 3.1 逻辑复制冲突

### 3.1.1 背景说明

在对同一个表进行逻辑复制的过程中，不出现冲突，上述部分表数据的表现也会在以下3个场景中有不同的呈现：

1. 发布端无操作
2. 发布端操作发布表
3. 发布端操作非发布表

而在逻辑复制不同的阶段（`pg_subscription_rel` 表属性 `srsubstate`）出现冲突，上述表数据的表现也会在以下3个场景中有不同的呈现：

1. 状态 'i' 或 'd'
2. 状态 's'
3. 状态 'r'

本方案是基于，在发布端无操作的背景下，1个发布者与1个订阅者，模拟冲突采集的数据展开的设计。

**注意：**逻辑复制存在两个程序内部状态（'w' 与 'c'），对外呈现状态也为 'd' 。依赖对逻辑复制进程打断点抓取，暂未展开测试。本方案考虑后续从代码流程分析，来确认这两个状态下出现冲突，其关键数据表现是否与'd'状态表冲突的数据表现重合。

### 3.1.2 数据分析

逻辑复制冲突，将导致订阅端对应的逻辑复制进程周期性（wal_retrieve_retry_interval）重启，在冲突解决之前，进程存活时间极短（165ms）。

```shell
2019-06-28 02:24:03.436 PDT [128246] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
2019-06-28 02:24:03.609 PDT [128246] ERROR:  duplicate key value violates unique constraint "tbl4_pkey"
2019-06-28 02:24:03.609 PDT [128246] DETAIL:  Key (id)=(20721) already exists.
2019-06-28 02:24:03.609 PDT [128246] CONTEXT:  COPY tbl4, line 1
2019-06-28 02:24:03.611 PDT [128231] LOG:  worker process: logical replication worker for subscription 51959 sync 43822 (PID 128246) exited with exit code 1
2019-06-28 02:24:09.079 PDT [128248] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
2019-06-28 02:24:09.227 PDT [128248] ERROR:  duplicate key value violates unique constraint "tbl4_pkey"
2019-06-28 02:24:09.227 PDT [128248] DETAIL:  Key (id)=(29601) already exists.
2019-06-28 02:24:09.227 PDT [128248] CONTEXT:  COPY tbl4, line 1
2019-06-28 02:24:09.230 PDT [128231] LOG:  worker process: logical replication worker for subscription 51959 sync 43822 (PID 128248) exited with exit code 1
2019-06-28 02:24:14.262 PDT [128250] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
```



## 3.2 订阅端PG进程异常/网络故障

订阅端PG进程异常，将导致发布端逻辑复制进程无法与订阅端通信，逻辑复制失败。惟一的区别在于订阅端PG进程是否存活。故不需对它们两进行区分识别。

此异常将导致发布端逻辑复制进程终止，直至异常恢复后，收到订阅端创建逻辑槽的请求才会启动。采集的数据显示如下：

```sql
postgres=# SELECT * FROM pg_replication_slots;
 slot_name |  plugin  | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn 
-----------+----------+-----------+--------+----------+-----------+--------+------------+------+--------------+-------------+---------------------
 sub1      | pgoutput | logical   |  13212 | postgres | f         | f      |            |      |         1103 | 6/4625DB28  | 6/4625DB60
(1 row)

postgres=# SELECT * FROM pg_stat_replication;
 pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag |
 flush_lag | replay_lag | sync_priority | sync_state 
-----+----------+---------+------------------+-------------+-----------------+-------------+---------------+--------------+-------+----------+-----------+-----------+------------+-----------+
-----------+------------+---------------+------------
(0 rows)
```

可以看到

1. pg_replication_slots 中只剩下app进程数据，但属性（active='f'）
2. pg_stat_replication 中无数据

**注：**上述进程异常为进程终止（手动 pkill -9 或 pg_ctl stop）

## 3.3 订阅端逻辑复制进程异常

订阅端逻辑复制进程异常退出，将迅速（15ms）重启。

**sync进程异常：**

```
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:05 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:06 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:14 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:02 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:01:01 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:02 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63566  38174 86 20:43 ?        00:00:14 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
cituscl+  63575  61915  0 20:44 pts/1    00:00:00 grep --color=auto postgres
[cituscluster@center1 data]$ kill 63566
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:05 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:06 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:14 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:02 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:01:01 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:02 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63576  38174 92 20:44 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
cituscl+  63578  61915  0 20:44 pts/1    00:00:00 grep --color=auto postgres
[cituscluster@center1 data]$ kill 63576
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:05 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:06 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:14 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:02 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:01:01 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:02 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63579  38174 17 20:44 ?        00:00:01 postgres: autovacuum worker process   postgres
cituscl+  63580  38174  0 20:44 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
cituscl+  63582  61915  0 20:44 pts/1    00:00:00 grep --color=auto postgres
[cituscluster@center1 data]$ kill 63580
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:05 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:06 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:14 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:02 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:01:01 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:02 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63579  38174 14 20:44 ?        00:00:03 postgres: autovacuum worker process   postgres
cituscl+  63585  38174 91 20:44 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
cituscl+  63587  61915  0 20:44 pts/1    00:00:00 grep --color=auto postgres
```

**app进程异常：**

```
[cituscluster@center1 ~]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:03 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:05 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:09 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:00:51 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:01 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  62226  38174  0 18:49 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76777  
cituscl+  62230  38174 93 18:49 ?        00:00:18 postgres: bgworker: logical replication worker for subscription 76777 sync 68425  
cituscl+  62240  61915  0 18:49 pts/1    00:00:00 grep --color=auto postgres
[cituscluster@center1 ~]$ kill 62226
[cituscluster@center1 ~]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  38176  38174  0 Jul13 ?        00:00:03 postgres: checkpointer process  
cituscl+  38177  38174  0 Jul13 ?        00:00:05 postgres: writer process   
cituscl+  38178  38174  0 Jul13 ?        00:00:09 postgres: wal writer process  
cituscl+  38179  38174  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  38180  38174  0 Jul13 ?        00:00:04 postgres: stats collector process  
cituscl+  38181  38174  0 Jul13 ?        00:00:51 postgres: bgworker: task tracker  
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  61558  61439  0 18:10 pts/3    00:00:02 psql -d postgres
cituscl+  61559  38174  0 18:10 ?        00:00:01 postgres: cituscluster postgres [local] idle
cituscl+  61886  61798  0 18:29 pts/5    00:00:00 psql -d postgres
cituscl+  61887  38174  0 18:29 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  62230  38174 92 18:49 ?        00:00:29 postgres: bgworker: logical replication worker for subscription 76777 sync 68425  
cituscl+  62242  38174  0 18:49 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76777  
cituscl+  62244  61915  0 18:49 pts/1    00:00:00 grep --color=auto postgres
```

**日志打印：**

```shell
[cituscluster@center1 data]$ kill 66339
[cituscluster@center1 data]$ 2019-07-15 00:38:22.311 PDT [66339] FATAL:  terminating logical replication worker due to administrator command
2019-07-15 00:38:22.315 PDT [66328] LOG:  worker process: logical replication worker for subscription 76791 (PID 66339) exited with exit code 1
2019-07-15 00:38:22.327 PDT [66360] LOG:  logical replication apply worker for subscription "sub1" has started
```

结合发布端的表数据，受订阅端异常的影响，发布端相应的逻辑复制进程（app WalSender进程 / sync WalSender进程）也会随之重启。

订阅端app逻辑复制进程故障恢复后，发布端显示，app进程的逻辑复制状态保持在 "catchup"，除非发布端触发增量同步。

**注：**上述进程异常为进程异常退出（手动 kill）

## 3.4 发布端PG进程异常/网络故障

发布端PG进程异常/网络故障，都将导致订阅端进程无法与发布端进行通信，逻辑复制失败。惟一的区别在于发布端PG进程是否存活。故不需对它们两进行区分识别。

通过日志观察发现，订阅端逻辑复制app进程将进入周期性（wal_retrieve_retry_interval）重启；但在与发布端通信恢复正常（稳定持续）之前，进程存活时间极短（3ms）。

订阅端逻辑复制sync进程退出后，将无法再次启动，直到与发布端通信恢复正常（稳定持续）。因此，异常期间app进程每次重启后存活时间过短，无法拉起sync进程。

```shell
2019-07-09 00:46:37.511 PDT [17875] LOG:  worker process: logical replication worker for subscription 68559 (PID 21336) exited with exit code 1
2019-07-09 00:46:42.526 PDT [21346] LOG:  logical replication apply worker for subscription "sub1" has started
2019-07-09 00:46:42.528 PDT [21346] ERROR:  could not connect to the publisher: could not connect to server: Connection refused
		Is the server running on host "192.168.221.131" and accepting
		TCP/IP connections on port 5432?
2019-07-09 00:46:42.529 PDT [17875] LOG:  worker process: logical replication worker for subscription 68559 (PID 21346) exited with exit code 1
2019-07-09 00:46:47.544 PDT [21347] LOG:  logical replication apply worker for subscription "sub1" has started
```

**注：**上述进程异常为进程终止（手动 pkill -9 或 pg_ctl stop）

## 3.5 发布端逻辑复制进程异常

发布端逻辑复制进程异常退出，将迅速（24ms）重启。

**sync进程对应的WalSender异常：**

```shell
[cituscluster@gtm2 ~]$ ps -ef | grep postgres
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  40372  40370  0 Jul13 ?        00:00:00 postgres: checkpointer process  
cituscl+  40373  40370  0 Jul13 ?        00:00:03 postgres: writer process   
cituscl+  40374  40370  0 Jul13 ?        00:00:02 postgres: wal writer process  
cituscl+  40375  40370  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  40376  40370  0 Jul13 ?        00:00:03 postgres: stats collector process  
cituscl+  40377  40370  0 Jul13 ?        00:00:50 postgres: bgworker: task tracker  
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63381  63261  0 18:11 pts/0    00:00:01 psql -d postgres
cituscl+  63382  40370  0 18:11 ?        00:00:03 postgres: cituscluster postgres [local] idle
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64071  40370 10 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51478) COPY
cituscl+  64089  63620  0 18:42 pts/2    00:00:00 grep --color=auto postgres
[cituscluster@gtm2 ~]$ kill 64071
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  40372  40370  0 Jul13 ?        00:00:00 postgres: checkpointer process  
cituscl+  40373  40370  0 Jul13 ?        00:00:03 postgres: writer process   
cituscl+  40374  40370  0 Jul13 ?        00:00:02 postgres: wal writer process  
cituscl+  40375  40370  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  40376  40370  0 Jul13 ?        00:00:03 postgres: stats collector process  
cituscl+  40377  40370  0 Jul13 ?        00:00:50 postgres: bgworker: task tracker  
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63381  63261  0 18:11 pts/0    00:00:01 psql -d postgres
cituscl+  63382  40370  0 18:11 ?        00:00:03 postgres: cituscluster postgres [local] idle
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64093  40370 14 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51480) COPY
cituscl+  64096  63620  0 18:42 pts/2    00:00:00 grep --color=auto postgre
[cituscluster@gtm2 ~]$ kill 64093
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  40372  40370  0 Jul13 ?        00:00:00 postgres: checkpointer process  
cituscl+  40373  40370  0 Jul13 ?        00:00:03 postgres: writer process   
cituscl+  40374  40370  0 Jul13 ?        00:00:02 postgres: wal writer process  
cituscl+  40375  40370  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  40376  40370  0 Jul13 ?        00:00:03 postgres: stats collector process  
cituscl+  40377  40370  0 Jul13 ?        00:00:50 postgres: bgworker: task tracker  
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63381  63261  0 18:11 pts/0    00:00:01 psql -d postgres
cituscl+  63382  40370  0 18:11 ?        00:00:03 postgres: cituscluster postgres [local] idle
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64111  40370 12 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51482) COPY
cituscl+  64114  63620  0 18:42 pts/2    00:00:00 grep --color=auto postgre
```

**app进程对应的WalSender异常：**

```
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  40372  40370  0 Jul13 ?        00:00:00 postgres: checkpointer process  
cituscl+  40373  40370  0 Jul13 ?        00:00:03 postgres: writer process   
cituscl+  40374  40370  0 Jul13 ?        00:00:02 postgres: wal writer process  
cituscl+  40375  40370  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  40376  40370  0 Jul13 ?        00:00:03 postgres: stats collector process  
cituscl+  40377  40370  0 Jul13 ?        00:00:50 postgres: bgworker: task tracker  
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63381  63261  0 18:11 pts/0    00:00:01 psql -d postgres
cituscl+  63382  40370  0 18:11 ?        00:00:03 postgres: cituscluster postgres [local] idle
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64111  40370 10 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51482) COPY
cituscl+  64121  63620  0 18:42 pts/2    00:00:00 grep --color=auto postgre
[cituscluster@gtm2 ~]$ kill 64013
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
cituscl+  40372  40370  0 Jul13 ?        00:00:00 postgres: checkpointer process  
cituscl+  40373  40370  0 Jul13 ?        00:00:03 postgres: writer process   
cituscl+  40374  40370  0 Jul13 ?        00:00:02 postgres: wal writer process  
cituscl+  40375  40370  0 Jul13 ?        00:00:01 postgres: autovacuum launcher process  
cituscl+  40376  40370  0 Jul13 ?        00:00:03 postgres: stats collector process  
cituscl+  40377  40370  0 Jul13 ?        00:00:50 postgres: bgworker: task tracker  
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63381  63261  0 18:11 pts/0    00:00:01 psql -d postgres
cituscl+  63382  40370  0 18:11 ?        00:00:03 postgres: cituscluster postgres [local] idle
cituscl+  64111  40370  9 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51482) COPY
cituscl+  64128  40370  0 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51484) idle
cituscl+  64131  63620  0 18:42 pts/2    00:00:00 grep --color=auto postgre
```

**发布端日志打印：**

```shell
[cituscluster@gtm2 ~]$ ps -ef | grep postgres
cituscl+  63381  63261  0 Jul14 pts/0    00:00:05 psql -d postgres
cituscl+  69682      1  0 00:37 pts/2    00:00:00 /opt/pgsql-10.1/bin/postgres
cituscl+  69684  69682  0 00:37 ?        00:00:00 postgres: checkpointer process  
cituscl+  69685  69682  0 00:37 ?        00:00:00 postgres: writer process   
cituscl+  69686  69682  0 00:37 ?        00:00:00 postgres: wal writer process  
cituscl+  69687  69682  0 00:37 ?        00:00:00 postgres: autovacuum launcher process  
cituscl+  69688  69682  0 00:37 ?        00:00:00 postgres: stats collector process  
cituscl+  69689  69682  0 00:37 ?        00:00:00 postgres: bgworker: task tracker  
cituscl+  69690  69682  0 00:37 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  69691  69682  0 00:37 ?        00:00:00 postgres: cituscluster postgres [local] idle
cituscl+  69692  69682  0 00:37 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51594) idle
cituscl+  69694  63620  0 00:38 pts/2    00:00:00 grep --color=auto postgres
[cituscluster@gtm2 ~]$ kill 69692
[cituscluster@gtm2 ~]$ 2019-07-15 00:38:12.406 PDT [69692] FATAL:  terminating connection due to administrator command
2019-07-15 00:38:12.440 PDT [69695] LOG:  starting logical decoding for slot "sub1"
2019-07-15 00:38:12.440 PDT [69695] DETAIL:  streaming transactions committing after 6/46262FD8, reading WAL from 6/46262FA0
2019-07-15 00:38:12.440 PDT [69695] LOG:  logical decoding found consistent point at 6/46262FA0
2019-07-15 00:38:12.440 PDT [69695] DETAIL:  There are no running transactions.
```

结合订阅端的表数据中可以发现，受发布端异常的影响，订阅端相应的逻辑复制进程（app进程 / sync进程）也会随之重启。

```shell
[cituscluster@center1 data]$ 2019-07-15 00:36:35.850 PDT [66338] ERROR:  could not receive data from WAL stream: FATAL:  terminating connection due to administrator command
2019-07-15 00:36:35.853 PDT [66328] LOG:  worker process: logical replication worker for subscription 76791 (PID 66338) exited with exit code 1
2019-07-15 00:36:35.866 PDT [66339] LOG:  logical replication apply worker for subscription "sub1" has started
```

**注意：**发布端app逻辑复制进程故障恢复后，app进程的逻辑复制状态将保持在 "catchup"，除非发布端触发增量同步。

```sql
postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |  state  |  sent_lsn  | write_lsn  | flus
h_lsn  | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+---------+------------+------------+-----
-------+------------+-----------+-----------+------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | catchup | 6/46260050 | 6/46260050 | 6/46
260050 | 6/46260050 |           |           |            |             0 | async
(1 row)

postgres=# insert into tbl1 values(1234567,1234);
INSERT 0 1
postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |   state   |  sent_lsn  | write_lsn  | fl
ush_lsn  | replay_lsn |    write_lag    |    flush_lag    |   replay_lag    | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+-----------+------------+------------+---
---------+------------+-----------------+-----------------+-----------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | streaming | 6/462629B8 | 6/462629B8 | 6/
462629B8 | 6/462629B8 | 00:00:00.006074 | 00:00:00.407596 | 00:00:00.006074 |             0 | async
(1 row)

postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |   state   |  sent_lsn  | write_lsn  | fl
ush_lsn  | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+-----------+------------+------------+---
---------+------------+-----------+-----------+------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | streaming | 6/46262A98 | 6/46262A98 | 6/
46262A98 | 6/46262A98 |           |           |            |             0 | async
(1 row)
```

**注：**上述进程异常为进程异常退出（手动 kill）

# 四、方案实现

## 4.1 参考数据

从各异常场景采集的数据可以发现，以下几张表、视图的数据表现，可以区分部分异常场景。

发布端：

1. pg_stat_replication
2. pg_replication_slots

订阅端：

1. pg_subscription_rel
2. pg_stat_subscription

**注：**对表以及表属性的筛选分析详见《逻辑复制异常场景表数据分析》

结合章节三中对各异常场景采集数据的分析，逻辑复制冲突时，发布端表现出的相关数据特性与订阅端相似；此外，订阅端还有更多可供参考的数据现象。所以，本方案将基于订阅端数据展开冲突检测。

## 4.2 思路设计

### 4.2.1 存储结构

链表 subscription_stat_list 保存逻辑复制进程信息，既有订阅者及订阅表相关数据及状态，也有用于该进程状态识别的相关计数。

数据结构定义如下：

```c++
List *subscription_stat_list = NULL;  // 自定义链表（SubscriptionStat）

typedef struct SubscriptionStat
{
    int           logicalId;       // 逻辑复制id
    Oid	          subid;           // 订阅者id
	Oid		      relid;           // 订阅表id：app进程此属性为默认值
	char		  relstate;        // 订阅表复制状态：app进程此属性为默认值
    char          workerstate;     // 订阅者逻辑复制进程状态
	char         *subname;         // 订阅者逻辑复制进程名
    int           pid;             // 订阅者逻辑复制进程pid：进程未启动或终止时此属性为默认值0
	List         *publishers;      // 订阅者关联的发布者列表（PublicationInfo）
    bool          disabled;        // 逻辑复制进程被 disable
    bool          fault;           // 逻辑复制进程出现故障：为true时后续不再走故障裁定流程
    bool          finished;        // 逻辑复制进程正常结束：为true时将不再监控此进程
	SubStateInfo  stateinfo;       // 订阅者逻辑复制进程状态信息
}SubscriptionStat;

typedef struct PublicationInfo
{
 	char       *nodeip;           // 发布节点ip
    int         nodeport;         // 发布节点port
    char       *pubname;          // 发布者名字
}PublicationInfo;

typedef struct SubStateInfo
{
	int			start_count;       // 逻辑复制进程启动次数
    int         disconnect_count;  // 通信异常次数
    int         normal_count;      // 进程正常次数
	int			abnormal_count;    // 进程确认异常次数
	bool		abnormal_check;    // 是否启动异常检测
	List       *ready_tables;      // app进程终止时对应订阅者的'r'状态表 relid
}SubStateInfo;
```

#### 4.2.1.1 数据初始化

执行在线迁移命令，启动逻辑复制后，将开启监控子进程。监控进程只监控与在线迁移有关的逻辑复制进程。

监控进程启动后，则执行以下操作，来完成监控数据的初始化。

1. 查询在线迁移功能自定义表 citus_remove_logical_rep_info ，获取当前在线迁移的发布者、订阅者信息（logicalId,sub_name,pub_name,source_node_name,source_node_port,target_node_name,target_node_port）

2. 以步骤1获取的信息为入参，通过自定义UDF函数向订阅端查询数据，涉及 pg_subscription、pg_subscription_rel、pg_stat_subscription 表或视图。
3. 将步骤1、2查询到的数据进行相关处理后，保存到自定义的存储结构 subscription_stat_list

存储结构关系如下图：

**注：**黄色框为主键；黄色虚线为相等项；箭头实线为数据赋值方向（箭头指向目的属性）

![1563763361098](https://github.com/MonkeyJane/citus/blob/master/FDD-Citus_dev/doc/pics/1563763361098.png?raw=true)

#### 4.2.1.2 数据更新

从 4.2.2 分析确定通过定时轮询机制，从在线迁移相关的发布端、订阅端获取信息。

在监控流程中完成对自定义存储结构 subscription_stat_list 的数据刷新。

#### 4.2.1.3 数据落盘

当监控流程 4.2.3.3 发现进程异常：某项异常计数从0变为有效值、某项异常标记位被设置；都会将此异常设置到自定义表 citus_remove_shard_statue 或 citus_remove_logical_rep_info 的属性（新增 is_fault），通过数值区分异常场景。

**citus_remove_logical_rep_info**
DISABLED : 命令行关闭
CONNECT_FAIL_CONFIRMED : 通信故障确认
CONNECT_FAIL_SUSPECTED : 通信故障可能存在

出现上述故障时：设置订阅者所有复制槽 is_fault 字段

**citus_remove_shard_statue** 
CONFLICT_CONFIRMED : 逻辑复制冲突确认
CONFLICT_SUSPECTED : 逻辑复制冲突可能存在

出现上述故障时：根据故障进程类型设置

**sync进程：**设置该进程对应的 shardid 数据 is_fault 字段

**app进程：**设置该订阅者对应的批量 shardid 数据 is_fault 字段

**注：**定时巡检机制的原生缺陷，可能导致在PG进程或监控进程故障退出时，尚未感知到逻辑复制异常。此时无需考虑 is_fault 字段未落盘的问题。

### 4.2.2 感知方式

执行在线迁移命令，启动逻辑复制后，开启监控子进程，抓取逻辑复制相关数据实现监控。

查询在线迁移功能自定义表的数据，掌握当前在线迁移涉及的订阅者以及订阅表。监控进程只关注这些订阅者及逻辑复制进程的数据变更。

#### 4.2.2.1 感知 pg_stat_subscription 变更

pg_stat_subscription 是一个视图，无法建立数据变更触发器，只能通过定时轮询获取数据。

它不保存实际数据，是 pg_subscription 表数据 LEFT JION 函数 pg_stat_get_subscription 中筛选的数据（ LogicalRepCtx->workers 中进程数据存在的进程），对外呈现。

当逻辑复制进程退出时，将触发 logicalrep_worker_onexit -> logicalrep_worker_cleanup 重置 LogicalRepCtx->workers 该进程的数据。

因此，只有正在运行的逻辑复制进程（app进程 & sync进程）可以查询，退出的进程无法查询。如果订阅者正在运行的逻辑复制进程数为0，返回的是该订阅者的基本信息（subid & subname），也可理解为app进程的基本信息。

从章节三给出的数据不难看出，异常场景下，逻辑复制进程可能会频繁重启，且重启后存活时间极短。异常进程数据在 pg_stat_subscription 中可见的时间极短，为了多捕捉到进程数据、尽快确认异常，定时器轮询周期需要比较短。

#### 4.2.2.2 感知 pg_subscription_rel 变更 

pg_subscription_rel 表存储着当前节点上订阅的所有表的相关数据，也即1张订阅表对应1条记录。作为自定义存储结构  subscription_stat_list 元素来源，表中数据的增删、复制状态的变更都应同步到 subscription_stat_list 。

基于 4.2.2.1 采用的轮询定时器，定时查询 pg_subscription_rel 数据。考虑到表的增删频率不会很高，因此轮询周期可以长于 pg_stat_subscription 的周期。

**注：**app进程不处理具体某一个订阅表，在 pg_subscription_rel 中没有对应的数据；app进程数据将在 4.2.2.1 中保存到 subscription_stat_list 

#### 4.2.2.3 感知逻辑复制进程状态变更

定时轮询的 pg_stat_subscription  数据与自定义存储结构 subscription_stat_list 中同一个逻辑复制进程元素进行比较，可以识别进程状态。  

1. pid 不同（有效值 vs 0）：进程启动（不区分是初次启动还是重启）
2. pid 不同（有效值1 vs 有效值2）：进程重启（进程终止到重启间隔太短，定时轮询未捕捉到终止）
3. pid 不同（空/查不到 vs 有效值）：进程终止
4. pid 相同（有效值 vs 有效值）：进程存活
5. pid 相同（空/查不到 vs 0）：进程未启动 或 进程反复重启（进程启动到终止间隔太短，定时轮询未捕捉到启动）

场景6的两种状态，需要通过其他手段来甄别。

**sync进程：**

定时轮询 pg_subscription_rel 过程中，第一次发现sync进程的表复制状态为 'd' ；发现 subscription_stat_list 中该进程 （pid==0 && start_count==0 && stop_count==0），则确认进程启动后异常退出，两次状态定时轮询均未捕捉到。

进行以下操作：

1. 累加 start_count  stop_count

2. 统计此时 pg_subscription_rel 中该订阅者名下非 'r' 状态订阅表数量，进行判断：

- 若（订阅表数量 <= max_sync_workers_per_subscription），则认为该sync进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该sync进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

当某sync进程（wait_abnormal_check==true），则每次轮询中都将重复步骤2，直到（订阅表数量 <= max_sync_workers_per_subscription），设置 abnormal_check，并重置 wait_abnormal_check

**app进程：**

定时轮询 pg_stat_subscription 过程中，第一次发现app进程的pid为空；发现 subscription_stat_list 中该进程 （pid==0 && start_count==0 && stop_count==0），无法确定是app进程尚未启动还是app进程已终止。

进行以下操作：

1. 统计此时 pg_stat_subscription 中在运行的app进程（pid=有效值）数量，进行判断：

- 若（进程数量 < max_replication_slots），则认为该app进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该app进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

则确认进程启动后异常退出，两次状态定时轮询均未捕捉到。

进行以下操作：

1. 累加 start_count  stop_count
2. 统计此时 pg_stat_subscription 中在运行的app进程（pid=有效值）数量，进行判断：

- 若（进程数量 < max_replication_slots），则认为该app进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该app进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

当某app进程（wait_abnormal_check==true），则每次轮询中都将重复步骤2，直到（进程数量 < max_replication_slots），设置 abnormal_check，并重置 wait_abnormal_check



当发现出现进程变更，就触发冲突识别流程。

**注：**定时轮询周期的选择！！是否会造成对异常场景的误判？！漏判？！定时器精度误差对冲突判断得影响？！都需进一步分析



### 4.2.3 识别流程

#### 4.2.3.1 app进程冲突识别

当某张订阅表（'r'状态表）进行逻辑复制时出现数据冲突，将触发app进程周期性（wal_retrieve_retry_interval）重启。

##### 4.2.3.1.1 冲突源识别

冲突源为 pg_subscription_rel 表中该订阅者名下'r'状态的订阅表。

**注：**暂时没想到在多个'r'状态表中定位到某个表的方法

##### 4.2.3.1.2 冲突源复制状态识别

冲突源的复制状态为 'r'。

##### 4.2.3.1.3 冲突场景识别

通过 4.2.3.3 识别到app进程终止或重启，需启动对app进程冲突的检测。app进程冲突与以下场景数据表现相同，需综合考虑区分。

1. 订阅端执行 ALTER SUBSCRIPTION xxx DISABLE
2. 发布端PG进程异常
3. 发布端逻辑复制进程异常
4. 网络故障

**场景1：**根据 subname 查询 pg_subscription 表属性（subenabled），此时 subenabled='f'。

处理：上述现象确认后，即可确认场景，重置该app进程所有异常计数

**场景2：**需在排除场景1后。根据 subname 查询  pg_subscription 表属性（subconninfo）与发布端通信，此时通信会失败。

处理：上述现象确认累计达到 app冲突裁定阈值，才能确认场景，重置该app进程所有异常计数

**场景4：**同场景2

**场景3：**需在排除场景1 & 场景2 & 场景4后。设置异常检测标记 abnormal_check，在 4.2.3.4 中判断，运用 app冲突裁定阈值 进行区分（是订阅端逻辑复制冲突还是发布端逻辑复制进程异常）。

**注：**为区分场景3，应设置 app冲突裁定阈值 * 轮询周期 > 逻辑复制进程恢复所需时长

#### 4.2.3.2 sync进程冲突

当某张订阅表（非'r'状态表）进行逻辑复制时出现数据冲突，将触发此表对应的sync进程周期性（wal_retrieve_retry_interval）重启。

##### 4.2.3.2.1 冲突源识别

冲突源为确认存在逻辑复制冲突的sync进程对应的 relid。

##### 4.2.3.2.2 冲突源复制状态识别

4.2.2.2 中第一次识别到sync进程重启或者退出，则查询 pg_subscription_rel 表中该订阅表状态（srsubstate）保存到 substate。对于'd'状态，只有在sync进程重启时，才能

##### 4.2.3.2.2 冲突场景识别

通过 4.2.3.3 识别到sync进程终止或重启，需启动对sync进程冲突的检测。sync进程冲突与以下场景数据表现相同，需综合考虑区分。

1. 发布端PG进程异常
2. 网络故障

**场景1：**根据 subname 查询  pg_subscription 表属性（subconninfo）与发布端通信，此时通信会失败。

处理：上述现象确认累计达到 sync冲突裁定阈值，才能确认场景，重置该sync进程所有异常计数

**场景2：**同场景1

排除上述场景，则进行冲突判断，详见 4.2.3.4。

#### 4.2.3.3 故障恢复

故障消失后，逻辑复制进程将恢复正常工作。sync进程将在逻辑复制工作完成（对应订阅表复制状态达到 's'）后正常退出；app进程将保持在线，直到命令行删除或关闭订阅者，进程才会退出。

基于逻辑复制状态监控流程（见 4.2.3.4），可以在 4.2.3.4.4 及时感知到故障恢复。

#### 4.2.3.4 监控流程

基于 4.2.2.3 识别的进程状态对自定义数据结构中元素的属性进行相关操作，以及相关数据的获取。

##### 4.2.3.4.1 进程启动

1. 设置进程id（pid）
2. 若进程处于故障状态（fault），则退出
3. 若进程处于关闭状态（disabled），则重置标记位（disabled=false）
4. 若进程处于等待故障检测状态（wait_abnormal_check），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）
5. 累加启动次数（start_count）
6. 若终止次数（start_count-1）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）

##### 4.2.3.4.2 进程重启

1. 设置进程id（pid）
2. 重置状态正常计数（normal_count=0）
3. 若进程处于故障状态（fault），则退出
4. 若进程处于关闭状态（disabled），则重置标记位（disabled=false）
5. 累加该relid的启动次数 start_count
6. 若**终止次数（start_count-1）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**

##### 4.2.3.4.3 进程终止

1. 设置进程id（pid）

2. 重置状态正常计数（normal_count=0）

3. 若为app进程（relid=NULL），则查询 pg_subscription 表中该订阅者状态（subenabled）

   3.1 **若（!subenabled），则报警，并设置标记位（disabled=true）。若进程当前状态正常（!fault），则清空状态计数（stateinfo）**

   3.2 若不满足3.1，则尝试与发布端通信。若通信失败，则累加通信异常计数（disconnect_count）；反之则累加进程故障计数（abnormal_count）。当**异常计数（disconnect_count或abnormal_count）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**，然后退出

   3.3 统计当前在运行的app进程（pid=有效值）数量，若小于配置项（max_replication_slots），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）；反之则更新为（wait_abnormal_check=true, abnormal_check=false）

4. 若为sync进程（relid=有效值），如果当前没有获取 pg_subscription_rel 表数据，则主动查询该订阅者所有数据

   4.1 **若该进程逻辑复制结束（srsubstate=='s'||srsubstate==‘r’），则更新标记位（finished=true** 
   **fault=false disabled=false），并清空状态计数（stateinfo）**

   4.2 若不满足4.1，则设置进程订阅表状态（relstate），依次进行3.1与3.2流程。

   4.3 若4.2未退出流程，则统计当前该订阅者名下未完成逻辑复制（srsubstate!='s'&&srsubstate!=‘r’）的订阅表数量。若小于等于配置项（max_sync_workers_per_subscription），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）；反之则更新为（wait_abnormal_check=true, abnormal_check=false）

##### 4.2.3.4.4 进程存活

1. 若进程处于故障检测阶段（abnormal_check）或者处于故障状态（fault），则累加状态正常计数（normal_count）
2. 若**正常计数（normal_count）超过故障恢复阈值，则认为故障已恢复。若进程处于故障状态（fault），则清除报警。重置标志位（fault=false abnormal_check=false wait_abnormal_check=false）**

##### 4.2.3.4.5 进程未启动

1. 若进程处于故障状态（fault），则退出
2. 若进程处于关闭状态（disabled），则退出
3. 若进程处于故障检测阶段（abnormal_check），则尝试与发布端通信。若通信失败，则累加通信异常计数（disconnect_count）；反之则累加进程故障计数（abnormal_count）。当**异常计数（disconnect_count或abnormal_count）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**，然后退出
4. 若进程处于等待故障检测状态（wait_abnormal_check），则根据进程类型来选择执行 4.2.3.4.3 中3.3 或 4.3 流程

#### 4.2.3.5 监控进程重启

监控进程工作过程（见 4.2.3.4）中，会根据情况将相关异常信息（见 4.2.1.3）落盘。

PG进程重启后，监控进程重新启动。将从本地自定义表 citus_remove_shard_statue 中读取所有数据的属性（is_fault）。根据异常值作相应报警，提醒用户需自行确认是否存在相关故障。

