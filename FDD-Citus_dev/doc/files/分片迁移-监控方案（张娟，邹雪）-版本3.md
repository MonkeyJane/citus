# 一、背景

为实现在线分片迁移功能，需提供有效的分片迁移监控手段。支撑程序高度自动化的同时，向用户实时呈现分片迁移进度、状态，并尽快地识别迁移过程中的异常，来支持程序进行自动化处理或者通知用户手动处理。

# 二、需求

我们基于PG逻辑复制机制，实现分片迁移功能。在分片源节点创建发布者来发布该分片，在目的节点创建该发布者的订阅者，即可完成分片数据的迁移。

分片迁移状态：PG原生 `pg_subscription_rel` 表中已提供属性`srsubstate`来展现订阅表的逻辑复制状态，该属性可用于分片迁移状态。因此对分片迁移状态的实现不作分析。

分片迁移进度：通过SQL实时在目的节点查询该分片大小呈现，具体SQL方案暂未确定，暂不讨论。

分片迁移异常可重入：需将异常场景相关数据保存到数据库中，进行处理。本方案中暂不讨论。

分片迁移异常：可能导致迁移失败、甚至是恢复后的重入操作。本方案将针对异常场景及场景的识别区分，进行重点分析。

涉及以下6个异常场景：（网络故障场景暂未模拟）

1. 订阅端某订阅表（1个或多个）逻辑复制冲突
2. 订阅端PG进程异常 / 网络故障
3. 订阅端某逻辑复制进程（1个或多个）异常
4. 发布端PG进程异常 / 网络故障
5. 发布端某逻辑复制进程（1个或多个）异常
6. 订阅端关闭逻辑复制（执行DISABLE命令）

# 三、场景分析

逻辑复制过程中，通过抓取发布端、订阅端日志记录，并在两端定时执行SQL抓取相关表数据，来分析异常场景。

```sql
## 发布端
select * from pg_publication_rel;
select * from pg_stat_replication;
select * from pg_replication_slots;
select * from pg_publication_tables;

## 订阅端
select * from pg_subscription;
select * from pg_subscription_rel;
select * from pg_stat_subscription;
select * from pg_replication_origin_status;
```

## 3.1 逻辑复制冲突

### 3.1.1 背景说明

在对同一个表进行逻辑复制的过程中，不出现冲突，上述部分表数据的表现也会在以下3个场景中有不同的呈现：

1. 发布端无操作
2. 发布端操作发布表
3. 发布端操作非发布表

而在逻辑复制不同的阶段（`pg_subscription_rel` 表属性 `srsubstate`）出现冲突，上述表数据的表现也会在以下3个场景中有不同的呈现：

1. 状态 'i' 或 'd'
2. 状态 's'
3. 状态 'r'

本方案是基于，在发布端无操作的背景下，1个发布者与1个订阅者，模拟冲突采集的数据展开的设计。

**注意：**逻辑复制存在两个程序内部状态（'w' 与 'c'），对外呈现状态也为 'd' 。依赖对逻辑复制进程打断点抓取，暂未展开测试。本方案考虑后续从代码流程分析，来确认这两个状态下出现冲突，其关键数据表现是否与'd'状态表冲突的数据表现重合。

### 3.1.2 数据分析

逻辑复制冲突，将导致订阅端对应的逻辑复制进程周期性（wal_retrieve_retry_interval）重启，在冲突解决之前，进程存活时间极短（165ms）。

```shell
2019-06-28 02:24:03.436 PDT [128246] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
2019-06-28 02:24:03.609 PDT [128246] ERROR:  duplicate key value violates unique constraint "tbl4_pkey"
2019-06-28 02:24:03.609 PDT [128246] DETAIL:  Key (id)=(20721) already exists.
2019-06-28 02:24:03.609 PDT [128246] CONTEXT:  COPY tbl4, line 1
2019-06-28 02:24:03.611 PDT [128231] LOG:  worker process: logical replication worker for subscription 51959 sync 43822 (PID 128246) exited with exit code 1
2019-06-28 02:24:09.079 PDT [128248] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
2019-06-28 02:24:09.227 PDT [128248] ERROR:  duplicate key value violates unique constraint "tbl4_pkey"
2019-06-28 02:24:09.227 PDT [128248] DETAIL:  Key (id)=(29601) already exists.
2019-06-28 02:24:09.227 PDT [128248] CONTEXT:  COPY tbl4, line 1
2019-06-28 02:24:09.230 PDT [128231] LOG:  worker process: logical replication worker for subscription 51959 sync 43822 (PID 128248) exited with exit code 1
2019-06-28 02:24:14.262 PDT [128250] LOG:  logical replication table synchronization worker for subscription "sub1", table "tbl4" has started
```

## 3.2 订阅端PG进程异常/网络故障

订阅端PG进程异常，将导致发布端逻辑复制进程无法与订阅端通信，逻辑复制失败。惟一的区别在于，订阅端PG进程是否存活，因此不需对它们两进行区分识别。

此异常将导致发布端逻辑复制进程终止，直至异常恢复后，收到订阅端创建逻辑槽的请求才会启动。采集的数据显示如下：

```sql
postgres=# SELECT * FROM pg_replication_slots;
 slot_name |  plugin  | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn 
-----------+----------+-----------+--------+----------+-----------+--------+------------+------+--------------+-------------+---------------------
 sub1      | pgoutput | logical   |  13212 | postgres | f         | f      |            |      |         1103 | 6/4625DB28  | 6/4625DB60
(1 row)

postgres=# SELECT * FROM pg_stat_replication;
 pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag |
 flush_lag | replay_lag | sync_priority | sync_state 
-----+----------+---------+------------------+-------------+-----------------+-------------+---------------+--------------+-------+----------+-----------+-----------+------------+-----------+
-----------+------------+---------------+------------
(0 rows)
```

可以看到：

1. pg_replication_slots 中只剩下app进程数据，但属性（active='f'）
2. pg_stat_replication 中无数据

**注：**上述进程异常为进程终止（手动 pkill -9 或 pg_ctl stop）

## 3.3 订阅端逻辑复制进程异常

订阅端逻辑复制进程异常退出，将迅速（15ms）重启。

**sync进程异常：**

```shell
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63566  38174 86 20:43 ?        00:00:14 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
[cituscluster@center1 data]$ kill 63566
[cituscluster@center1 data]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  63555  38174  0 20:43 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791  
cituscl+  63576  38174 92 20:44 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76791 sync 68425  
```

**app进程异常：**

```shell
[cituscluster@center1 ~]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
.........................................
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  62226  38174  0 18:49 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76777  
cituscl+  62230  38174 93 18:49 ?        00:00:18 postgres: bgworker: logical replication worker for subscription 76777 sync 68425  
[cituscluster@center1 ~]$ kill 62226
[cituscluster@center1 ~]$ ps -ef | grep postgres
cituscl+  38174      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
.........................................
cituscl+  38182  38174  0 Jul13 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  62230  38174 92 18:49 ?        00:00:29 postgres: bgworker: logical replication worker for subscription 76777 sync 68425  
cituscl+  62242  38174  0 18:49 ?        00:00:00 postgres: bgworker: logical replication worker for subscription 76777  
```

**app进程异常日志：**

```shell
[cituscluster@center1 data]$ kill 66339
[cituscluster@center1 data]$ 2019-07-15 00:38:22.311 PDT [66339] FATAL:  terminating logical replication worker due to administrator command
2019-07-15 00:38:22.315 PDT [66328] LOG:  worker process: logical replication worker for subscription 76791 (PID 66339) exited with exit code 1
2019-07-15 00:38:22.327 PDT [66360] LOG:  logical replication apply worker for subscription "sub1" has started
```

结合发布端的表数据与日志打印，发现受订阅端异常的影响，发布端相应的逻辑复制进程（app WalSender进程 / sync WalSender进程）也会随之重启。

订阅端app逻辑复制进程故障恢复后，发布端显示，app进程的逻辑复制状态保持在 "catchup"，除非发布端触发增量同步。

**注：**上述进程异常为进程异常退出（手动 kill）

## 3.4 发布端PG进程异常/网络故障

发布端PG进程异常/网络故障，都将导致订阅端进程无法与发布端进行通信，逻辑复制失败。惟一的区别在于发布端PG进程是否存活。故不需对它们两进行区分识别。

通过日志观察发现，订阅端逻辑复制app进程将进入周期性（wal_retrieve_retry_interval）重启；但在与发布端通信恢复正常（稳定持续）之前，进程存活时间极短（3ms）。

订阅端逻辑复制sync进程退出后，将无法再次启动，直到与发布端通信恢复正常（稳定持续）。因此，异常期间app进程每次重启后存活时间过短，无法拉起sync进程。

```shell
2019-07-09 00:46:37.511 PDT [17875] LOG:  worker process: logical replication worker for subscription 68559 (PID 21336) exited with exit code 1
2019-07-09 00:46:42.526 PDT [21346] LOG:  logical replication apply worker for subscription "sub1" has started
2019-07-09 00:46:42.528 PDT [21346] ERROR:  could not connect to the publisher: could not connect to server: Connection refused
		Is the server running on host "192.168.221.131" and accepting
		TCP/IP connections on port 5432?
2019-07-09 00:46:42.529 PDT [17875] LOG:  worker process: logical replication worker for subscription 68559 (PID 21346) exited with exit code 1
2019-07-09 00:46:47.544 PDT [21347] LOG:  logical replication apply worker for subscription "sub1" has started
```

**注：**上述进程异常为进程终止（手动 pkill -9 或 pg_ctl stop）

## 3.5 发布端逻辑复制进程异常

发布端逻辑复制进程异常退出，将迅速（24ms）重启。

**sync进程对应的WalSender异常：**

```shell
[cituscluster@gtm2 ~]$ ps -ef | grep postgres
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64071  40370 10 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51478) COPY
[cituscluster@gtm2 ~]$ kill 64071
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64093  40370 14 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51480) COPY
```

**app进程对应的WalSender异常：**

```shell
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  64013  40370  0 18:41 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51474) idle
cituscl+  64111  40370 10 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51482) COPY
[cituscluster@gtm2 ~]$ kill 64013
[cituscluster@gtm2 ~]$ ps -ef | grep postgre
cituscl+  40370      1  0 Jul13 ?        00:00:01 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  61786  40370  0 15:57 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  64111  40370  9 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51482) COPY
cituscl+  64128  40370  0 18:42 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51484) idle
```

**发布端日志：**

```shell
[cituscluster@gtm2 ~]$ ps -ef | grep postgres
cituscl+  69682      1  0 00:37 pts/2    00:00:00 /opt/pgsql-10.1/bin/postgres
......................................................
cituscl+  69690  69682  0 00:37 ?        00:00:00 postgres: bgworker: logical replication launcher  
cituscl+  69692  69682  0 00:37 ?        00:00:00 postgres: wal sender process cituscluster 192.168.221.132(51594) idle
[cituscluster@gtm2 ~]$ kill 69692
[cituscluster@gtm2 ~]$ 2019-07-15 00:38:12.406 PDT [69692] FATAL:  terminating connection due to administrator command
2019-07-15 00:38:12.440 PDT [69695] LOG:  starting logical decoding for slot "sub1"
2019-07-15 00:38:12.440 PDT [69695] DETAIL:  streaming transactions committing after 6/46262FD8, reading WAL from 6/46262FA0
2019-07-15 00:38:12.440 PDT [69695] LOG:  logical decoding found consistent point at 6/46262FA0
2019-07-15 00:38:12.440 PDT [69695] DETAIL:  There are no running transactions.
```

结合发布端的表数据与日志打印，发现受发布端异常的影响，订阅端相应的逻辑复制进程（app进程 / sync进程）也会随之重启。

```shell
[cituscluster@center1 data]$ 2019-07-15 00:36:35.850 PDT [66338] ERROR:  could not receive data from WAL stream: FATAL:  terminating connection due to administrator command
2019-07-15 00:36:35.853 PDT [66328] LOG:  worker process: logical replication worker for subscription 76791 (PID 66338) exited with exit code 1
2019-07-15 00:36:35.866 PDT [66339] LOG:  logical replication apply worker for subscription "sub1" has started
```

**注意：**发布端app逻辑复制进程故障恢复后，app进程的逻辑复制状态将保持在 "catchup"，除非发布端触发增量同步。

```sql
postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |  state  |  sent_lsn  | write_lsn  | flus
h_lsn  | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+---------+------------+------------+-----
-------+------------+-----------+-----------+------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | catchup | 6/46260050 | 6/46260050 | 6/46
260050 | 6/46260050 |           |           |            |             0 | async
(1 row)

postgres=# insert into tbl1 values(1234567,1234);
INSERT 0 1
postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |   state   |  sent_lsn  | write_lsn  | fl
ush_lsn  | replay_lsn |    write_lag    |    flush_lag    |   replay_lag    | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+-----------+------------+------------+---
---------+------------+-----------------+-----------------+-----------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | streaming | 6/462629B8 | 6/462629B8 | 6/
462629B8 | 6/462629B8 | 00:00:00.006074 | 00:00:00.407596 | 00:00:00.006074 |             0 | async
(1 row)

postgres=# SELECT * FROM pg_stat_replication;
  pid  | usesysid |   usename    | application_name |   client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |   state   |  sent_lsn  | write_lsn  | fl
ush_lsn  | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state 
-------+----------+--------------+------------------+-----------------+-----------------+-------------+-------------------------------+--------------+-----------+------------+------------+---
---------+------------+-----------+-----------+------------+---------------+------------
 64417 |       10 | cituscluster | sub1             | 192.168.221.132 |                 |       51500 | 2019-07-14 18:51:59.468038-07 |              | streaming | 6/46262A98 | 6/46262A98 | 6/
46262A98 | 6/46262A98 |           |           |            |             0 | async
(1 row)
```

**注：**上述进程异常为进程异常退出（手动 kill）

# 四、方案实现

## 4.1 参考数据

从各异常场景采集的数据可以发现，以下几张表、视图的数据表现，可以区分部分异常场景。

发布端：

1. pg_stat_replication
2. pg_replication_slots

订阅端：

1. pg_subscription_rel
2. pg_stat_subscription

**注：**对表以及表属性的筛选分析详见《逻辑复制异常场景表数据分析》

结合章节三中对各异常场景采集数据的分析，逻辑复制冲突时，发布端表现出的相关数据特性与订阅端相似；而且，订阅端有更多可供参考的数据现象。因此，本方案将以订阅端的数据为准，展开冲突检测。

作为在线迁移功能的子模块，逻辑复制监控基于在线迁移框架，在主CN上运行。主CN与逻辑复制的相关节点进行通信，进行任务分发与监控。因此，监控模块也需要考虑主CN通信问题对监控功能及在线迁移功能的影响。

**影响逻辑复制运行的场景：**

1. 执行命令行DISABLE逻辑复制
2. 订阅端PG进程/网络通信异常：主CN无法与订阅端通信、无法获取数据；主CN可以与发布端通信，可以获取数据，但相关数据为空
3. 订阅端逻辑复制进程异常：订阅端逻辑复制进程迅速重启（ms级）、重启间隔不受订阅端launcher轮询周期限制；如果异常未恢复，将反复此现象。发布端逻辑复制进程也会因此受影响
4. 订阅端逻辑复制进程冲突：逻辑复制进程重启、重启间隔受订阅端launcher轮询周期（默认5s）限制；如果异常未恢复，将反复此现象
5. 发布端PG进程/网络通信异常：主CN可以与订阅端通信，可以获取数据，但相关数据为空；主CN无法与发布端通信、无法获取数据
6. 发布端逻辑复制进程异常：订阅端逻辑复制进程迅速重启（ms级）、重启间隔不受订阅端launcher轮询周期限制；如果异常未恢复，将反复此现象。订阅端逻辑复制进程也会因此受影响
7. 主CN监控进程/网络通信异常：无法与订阅端以及发布端通信

**场景甄别：**

场景1：订阅端`pg_subscription_rel`表 isenable 属性可以体现是否被DISABLE

场景2：依赖主CN与发布端通信确认

场景3 & 场景4 & 场景6：监控功能作为在线迁移进程的子模块，轮询监控周期较长，无法捕捉到进程重启实际间隔时间。因此，无法区分冲突与异常；即使能实现，现有的数据信息也无法区分发布端与订阅端异常

场景5：依赖主CN与发布端通信确认

场景7：依赖主CN与发布端、订阅端通信确认

因此，除了从订阅端获取信息，主CN还需与发布端进行通信，才能实现异常场景的甄别。

为了获取一致性数据，新增UDF函数，主cn可以调用该函数，从订阅端获取表状态、进程状态等信息。

## 4.2 思路设计

### 4.2.1  新增UDF函数fdd_get_sub_status

新增函数`fdd_get_sub_status`，主要用于主cn从订阅端获取订阅者OID、复制槽、表同步状态以及复制进程状态等信息。

传入参数：

>sub_name        订阅者名字
>
>sub_id               订阅者OID，如果sub_id不为空，以sub_id为准，否则，以subname为准					 
>
>sub_rel_list       只返回指定的表状态，如果为空，获取sub_name对应的所有：用来扩展，一般传空
>only_relstatus  只关心表状态，不关心进程id和进程状态如果sub_name和sub_id都为空，报错；
>only_if_disable  只查询该订阅者是否被disable如果sub_id为空，首先遍历pg_subscription表，根据



**注**：从citus_remove_logical_rep_info表中获取订阅者信息，包括订阅者名字，订阅者ip和端口，由主cn连接订阅者，调用该UDF发起状态查询。



返回结果：

>sub_id                   订阅者oid
>
>subenabled         订阅者是否enable，同一个订阅者下，包含的所有表对应的值是一样的
>
>slot_name           复制槽名字，包括app和sync对应的
>
>sub_relid             订阅者包含的表oid
>
>slot_pid               复制槽对应的子进程（订阅端）
>
>slot_pstatus      复制槽对应的订阅端子进程的状态(app进程无法获得状态，其状态值一直为'\0'，rep_status是结合sync进程状态和表状态来判断)
>
>subrel_status    订阅端包含的表的状态



函数执行过程：

> (1)如果sub_id为空，首先遍历pg_subscription表，根据sub_name获取sub_id；检查订阅者是否disable，如果disable，直接返回一条记录，表明该订阅者已经被disable；如果不是disable，该订阅者包含的表该属性都是enable；
>
> (2)如果only_if_disable为true，返回；
>
> (3)如果sub_name为空，根据sub_/.. id获取sub_name；
>
> (4)遍历pg_subscription_rel，获取sub_id对应的relid和表状态，如果sub_rel_list不为空，获取指定的表；并且将sub_id+sub_name+relid组成的字符串作为表的sub_name；
>
> (5)如果only_relstatus为true，返回；
>
> (6)根据sub_id和上一步获取的relids，遍历共享内存LogicalRepCtx->workers，根据sub_id和relid获取匹配的pid和relstate，如果找不到，结果为null，注意app是sub_id匹配，relid为空；

**注**：过程中需要访问订阅端pg_subscription和pg_subscription_rel两个系统表，以及订阅端PG共享内存LogicalRepCtx->workers。

执行结果：

```sql
sub_id   |  sub_relid |  subenabled |      slot_name        |  slot_pid        | slot_pstatus   |  subrel_status
---------+------------+-------------+-----------------------+------------------+----------------+-------------
  5565   |  null   	  |  false   	| test                  |   12354785  	   | null           |   null
  5565   |  123200 	  |  false   	| test_5565_sync_123200 |   12354786  	   | process_statu1 |   ’d'
  5565   |  123201 	  |  false   	| test_5565_sync_123201 |   12354787  	   | process_statu2 |   ’d'
  5565   |  123202 	  |  false   	| test_5565_sync_123202 |   null      	   | null           |   'i'
```

### 4.2.2 存储结构

在线迁移自定义结构体 MoveWorker 保存了逻辑复制进程以及两端节点的基本信息，并通过成员变量HASH表，关联了逻辑复制分片相关的数据。

```c++
typedef struct MoveWorker
{
	int repid;                 // 待迁移分片所分配的复制任务处理子进程序号
	int pid;                   // 复制任务处理子进程的进程号
	char sub_name[NAME_LEN];   // 订阅者名字，阻塞写模式此处为空
	char pub_name[NAME_LEN];   // 发布者名字，阻塞写模式此处为空
	int source_groupid;        // 源节点组id
	int target_groupid;        // 目的节点组id
	int rep_state;             // 复制任务子进程的整体迁移进度
	
    //以下结构不会存到表中，只存在内存中
	bool isValid                      // 此条目是否收到缓存效通知，是否需要重构缓存
	char source_node_name[NAME_LEN];  // 待迁移分片所在的源节点的DNS名称
	int source_node_port;             // 数据库服务器正在侦听的源节点上的端口
	char target_node_name[NAME_LEN];  // 分片将迁移到目标节点的DNS名称
	int target_node_port;             // 数据库服务器正在侦听的目标节点上的端口。
	HTAB *PostedShards;               // key为relationId（订阅端分片表oid），entry为MoveShardCacheEntry
	bool enablePost;                  // 新增成员变量 : 是否允许分片投递
	RepStatInfo statInfo;             // 新增成员变量 : 复制任务子进程的监控计数
}MoveWorker;
```

在这个结构体中，加入新的成员变量，用于复制任务子进程的通信状态监控。

```c++
typedef struct RepStatInfo
{
	int pub_fail_count;
	int sub_fail_count;
	int pub_normal_count;
	int sub_normal_count;
}RepStatInfo;
```

在线迁移自定义结构体 MoveShardCacheEntry 保存了逻辑复制分片的基本信息与复制状态。

```c++
typedef struct MoveShardCacheEntry
{
	int shardid;            // 待移动的分片ID
	int groupid;            // 待迁移分片表所处的组id
	int repid;              // 待迁移分片所分配的复制任务处理子进程序号
	Oid tablename;          // 待迁移分片的表名（此行对应的分布式表。该值引用pg_class系统目录表中的relfilenode列）
	int taskid;             // 在线迁移任务id
	int64 assign_shardid;   // 是由哪个分片因为亲和关系，触发当前分片表进行迁移的，若当前值为shardid，则该行为分片迁移指定的分片
	int64 shard_size;       // 分片初始大小（以字节为单位）
	int stage_time;         // 当前状态开始的时间
	int shard_state;        // 该分片当前处于哪个迁移阶段
    
	// 以下结构不会存到表中，只存在内存中
	bool isValid;           // 此条目是否收到缓存效通知，是否需要重构缓存
	Oid relationId;         // 此分片表在订阅端上的oid
	SubscriptionStat subInfo;  // 新增成员变量 : 逻辑复制进程的监控数据
}MoveShardCacheEntry;
```

在这个结构体中，加入新的成员变量。保存进程状态识别的基本信息以及相关计数，用于逻辑复制状态监控。

```c++
typedef struct SubscriptionStat
{
    int         sub_pid;           // 订阅者逻辑复制进程pid：进程未启动或终止时此属性为默认值0
	int			start_count;       // 逻辑复制进程启动次数
    int         normal_count;      // 进程正常次数
	int			abnormal_count;    // 进程确认异常次数
	bool		abnormal_check;    // 是否启动异常检测
}SubscriptionStat;
```

此外，还需增加一个自定义结构体，用于保存轮询抓取到的数据。

```c++
typedef struct sub_status
{
     Oid  sub_id;
     Oid  relid;
     int  slot_pid;
     char slot_pstatus;
     char subrel_satus;
     char sub_name[NAME_LEN];
     char slot_name[NAME_LEN];
     bool  sub_enabled;
}sub_status;
```



#### 4.2.2.1 数据初始化

执行在线迁移命令，启动逻辑复制后，将开启监控子进程。监控进程只监控与在线迁移有关的逻辑复制进程。

监控进程启动后，则执行以下操作，来完成监控数据的初始化。

1. 查询在线迁移功能自定义表 citus_remove_logical_rep_info ，获取当前在线迁移的发布者、订阅者信息（logicalId,sub_name,pub_name,source_node_name,source_node_port,target_node_name,target_node_port）

2. 以步骤1获取的信息为入参，通过自定义UDF函数向订阅端查询数据，涉及 pg_subscription、pg_subscription_rel、pg_stat_subscription 表或视图。
3. 将步骤1、2查询到的数据进行相关处理后，保存到自定义的存储结构 subscription_stat_list

存储结构关系如下图：

**注：**黄色框为主键；黄色虚线为相等项；箭头实线为数据赋值方向（箭头指向目的属性）

![1563763361098](https://github.com/MonkeyJane/citus/blob/master/FDD-Citus_dev/doc/pics/1563763361098.png?raw=true)

#### 4.2.2.2 数据更新

从 4.2.3 分析选择通过定时轮询机制，从在线迁移相关的发布端、订阅端获取信息。

监控流程中完成对自定义存储结构 subscription_stat_list 的数据刷新。

#### 4.2.2.3 数据落盘

##### 4.2.2.3.1 异常展示

当监控流程 4.2.3.3 发现进程异常：某项异常计数从0变为有效值、某项异常标记位被设置；都会将此异常设置到自定义表 citus_remove_shard_statue 或 citus_remove_logical_rep_info 的属性（新增 is_fault），通过数值区分异常场景。

**citus_remove_logical_rep_info**
DISABLED : 命令行关闭
CONNECT_FAIL_CONFIRMED : 通信故障确认
CONNECT_FAIL_SUSPECTED : 通信故障可能存在

出现上述故障时：设置订阅者所有复制槽 is_fault 字段

**citus_remove_shard_statue** 
CONFLICT_CONFIRMED : 逻辑复制冲突确认
CONFLICT_SUSPECTED : 逻辑复制冲突可能存在

出现上述故障时：根据故障进程类型设置

**sync进程：**设置该进程对应的 shardid 数据 is_fault 字段

**app进程：**设置该订阅者对应的批量 shardid 数据 is_fault 字段

**注：**定时巡检机制的原生缺陷，可能导致在PG进程或监控进程故障退出时，尚未感知到逻辑复制异常。此时无需考虑 is_fault 字段未落盘的问题。

##### 4.2.2.3.2  逻辑复制阶段展示

对应citus_remove_shard_statues表的rep_status字段，主cn在遍历citus_remove_shard_statues，根据sub_name获取完数据之后，以logicid为单位，在SubscriptionStat中找到对应逻辑复制的所有数据，根据以下规则，结合表状态和进程状态，归纳出最终状态，对比原来rep_status字段并更新：

>Initial                    ：初始状态
>created_logical   ：创建了逻辑复制的发布端和订阅端
>
>Startup                ：该条逻辑复制槽正在进行存量更新操作，还没有表进入增量更新状态
>PART_Catchup    ：该条逻辑复制槽的订阅端中有SYNC进程正在进行追增量操作,但是还有部分进程在追存量或等待追存量
>Catchup              ：该条逻辑复制槽的订阅端中有SYNC进程正在进行追增量操作，剩下其他表都是由APP追增量
>Streaming         ：该逻辑复制槽只存在订阅端的APP进程追增量操作
>Move_end         ：逻辑复制已经完成，该条复制槽等待被移除，包括删除订阅端和发布端
>APP_ERR	   ：该条逻辑复制出现某种错误，APP退出，但是有sync进程在运行
>
>SYNC_ERR           :某个表的状态不为’r'，找不到对应的sync进程，但是有app进程或者其他sync进程在运行
>
>FETAL_ERR         : 该条逻辑复制没有完成，但是没有任何进程在运行

**注：**Move_end状态，在锁表和校验数据之后，由其他流程修改；在校验逻辑复制状态过程中，要对比原来的状态，原来的状态为Move_end之后，不需要再获取状态了

某一个logicid对应的逻辑复制可能出于以下阶段：

![rep_status](https://github.com/ZavierZX/picfiles/blob/master/rep_status.png?raw=true)

### 4.2.3 感知方式

执行在线迁移命令，启动逻辑复制后，开启监控子进程，抓取逻辑复制相关数据实现监控。

查询在线迁移功能自定义表的数据，掌握当前在线迁移涉及的订阅者以及订阅表。监控进程只关注这些订阅者及逻辑复制进程的数据变更。

#### 4.2.3.1 感知 pg_stat_subscription 变更

pg_stat_subscription 是一个视图，无法建立数据变更触发器，只能通过定时轮询获取数据。

它不保存实际数据，是 pg_subscription 表数据 LEFT JION 函数 pg_stat_get_subscription 中筛选的数据（ LogicalRepCtx->workers 中进程数据存在的进程），对外呈现。

当逻辑复制进程退出时，将触发 logicalrep_worker_onexit -> logicalrep_worker_cleanup 重置 LogicalRepCtx->workers 该进程的数据。

因此，只有正在运行的逻辑复制进程（app进程 & sync进程）可以查询，退出的进程无法查询。如果订阅者正在运行的逻辑复制进程数为0，返回的是该订阅者的基本信息（subid & subname），也可理解为app进程的基本信息。

从章节三给出的数据不难看出，异常场景下，逻辑复制进程可能会频繁重启，且重启后存活时间极短。异常进程数据在 pg_stat_subscription 中可见的时间极短，为了多捕捉到进程数据、尽快确认异常，定时器轮询周期需要比较短。

#### 4.2.3.2 感知 pg_subscription_rel 变更 

pg_subscription_rel 表存储着当前节点上订阅的所有表的相关数据，也即1张订阅表对应1条记录。作为自定义存储结构  subscription_stat_list 元素来源，表中数据的增删、复制状态的变更都应同步到 subscription_stat_list 。

基于 4.2.3.1 采用的轮询定时器，定时查询 pg_subscription_rel 数据。考虑到表的增删频率不会很高，因此轮询周期可以长于 pg_stat_subscription 的周期。

**注：**app进程不处理具体某一个订阅表，在 pg_subscription_rel 中没有对应的数据；app进程数据将在 4.2.3.1 中保存到 subscription_stat_list 

#### 4.2.3.3 感知逻辑复制进程状态变更

定时轮询的 pg_stat_subscription  数据与自定义存储结构 subscription_stat_list 中同一个逻辑复制进程元素进行比较，可以识别进程状态。  

1. pid 不同（有效值 vs 0）：进程启动（不区分是初次启动还是重启）
2. pid 不同（有效值1 vs 有效值2）：进程重启（进程终止到重启间隔太短，定时轮询未捕捉到终止）
3. pid 不同（空/查不到 vs 有效值）：进程终止
4. pid 相同（有效值 vs 有效值）：进程存活
5. pid 相同（空/查不到 vs 0）：进程未启动 或 进程反复重启（进程启动到终止间隔太短，定时轮询未捕捉到启动）

场景6的两种状态，需要通过其他手段来甄别。

**sync进程：**

定时轮询 pg_subscription_rel 过程中，第一次发现sync进程的表复制状态为 'd' ；发现 subscription_stat_list 中该进程 （pid==0 && start_count==0 && stop_count==0），则确认进程启动后异常退出，两次状态定时轮询均未捕捉到。

进行以下操作：

1. 累加 start_count  stop_count

2. 统计此时 pg_subscription_rel 中该订阅者名下非 'r' 状态订阅表数量，进行判断：

- 若（订阅表数量 <= max_sync_workers_per_subscription），则认为该sync进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该sync进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

当某sync进程（wait_abnormal_check==true），则每次轮询中都将重复步骤2，直到（订阅表数量 <= max_sync_workers_per_subscription），设置 abnormal_check，并重置 wait_abnormal_check

**app进程：**

定时轮询 pg_stat_subscription 过程中，第一次发现app进程的pid为空；发现 subscription_stat_list 中该进程 （pid==0 && start_count==0 && stop_count==0），无法确定是app进程尚未启动还是app进程已终止。

进行以下操作：

1. 统计此时 pg_stat_subscription 中在运行的app进程（pid=有效值）数量，进行判断：

- 若（进程数量 < max_replication_slots），则认为该app进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该app进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

则确认进程启动后异常退出，两次状态定时轮询均未捕捉到。

进行以下操作：

1. 累加 start_count  stop_count
2. 统计此时 pg_stat_subscription 中在运行的app进程（pid=有效值）数量，进行判断：

- 若（进程数量 < max_replication_slots），则认为该app进程在持续快速的重启。设置异常检测标记 **abnormal_check  ==>设置标记位后，每次未启动将累加 abnomal_count 达到阈值就告警**
- 若不满足条件，则认为该app进程在排队等待重启。设置等待异常检测标记 wait_abnormal_check

当某app进程（wait_abnormal_check==true），则每次轮询中都将重复步骤2，直到（进程数量 < max_replication_slots），设置 abnormal_check，并重置 wait_abnormal_check



当发现出现进程变更，就触发冲突识别流程。

**注：**定时轮询周期的选择！！是否会造成对异常场景的误判？！漏判？！定时器精度误差对冲突判断得影响？！都需进一步分析



### 4.2.4 识别流程

#### 4.2.4.1 app进程冲突识别

当某张订阅表（'r'状态表）进行逻辑复制时出现数据冲突，将触发app进程周期性（wal_retrieve_retry_interval）重启。

##### 4.2.4.1.1 冲突源识别

冲突源为 pg_subscription_rel 表中该订阅者名下'r'状态的订阅表。

**注：**暂时没想到在多个'r'状态表中定位到某个表的方法

##### 4.2.4.1.2 冲突源复制状态识别

冲突源的复制状态为 'r'。

##### 4.2.4.1.3 冲突场景识别

通过 4.2.4.3 识别到app进程终止或重启，需启动对app进程冲突的检测。app进程冲突与以下场景数据表现相同，需综合考虑区分。

1. 订阅端执行 ALTER SUBSCRIPTION xxx DISABLE
2. 发布端PG进程异常
3. 发布端逻辑复制进程异常
4. 网络故障

**场景1：**根据 subname 查询 pg_subscription 表属性（subenabled），此时 subenabled='f'。

处理：上述现象确认后，即可确认场景，重置该app进程所有异常计数

**场景2：**需在排除场景1后。根据 subname 查询  pg_subscription 表属性（subconninfo）与发布端通信，此时通信会失败。

处理：上述现象确认累计达到 app冲突裁定阈值，才能确认场景，重置该app进程所有异常计数

**场景4：**同场景2

**场景3：**需在排除场景1 & 场景2 & 场景4后。设置异常检测标记 abnormal_check，在 4.2.4.4 中判断，运用 app冲突裁定阈值 进行区分（是订阅端逻辑复制冲突还是发布端逻辑复制进程异常）。

**注：**为区分场景3与冲突场景，应设置 app冲突裁定阈值 * 轮询周期 > 逻辑复制进程恢复所需时长

#### 4.2.4.2 sync进程冲突

当某张订阅表（非'r'状态表）进行逻辑复制时出现数据冲突，将触发此表对应的sync进程周期性（wal_retrieve_retry_interval）重启。

##### 4.2.4.2.2 冲突源识别

冲突源为确认存在逻辑复制冲突的sync进程对应的 relid。

##### 4.2.4.2.3 冲突源复制状态识别

4.2.3.2 中第一次识别到sync进程重启或者退出，则查询 pg_subscription_rel 表中该订阅表状态（srsubstate）保存到 substate。对于'd'状态，只有在sync进程重启时，才能

##### 4.2.4.2.3 冲突场景识别

通过 4.2.4.3 识别到sync进程终止或重启，需启动对sync进程冲突的检测。sync进程冲突与以下场景数据表现相同，需综合考虑区分。

1. 发布端PG进程异常
2. 网络故障

**场景1：**根据 subname 查询  pg_subscription 表属性（subconninfo）与发布端通信，此时通信会失败。

处理：上述现象确认累计达到 sync冲突裁定阈值，才能确认场景，重置该sync进程所有异常计数

**场景2：**同场景1

排除上述场景，则进行冲突判断，详见 4.2.4.4。

#### 4.2.4.3 故障恢复

故障消失后，逻辑复制进程将恢复正常工作。sync进程将在逻辑复制工作完成（对应订阅表复制状态达到 's'）后正常退出；app进程将保持在线，直到命令行删除或关闭订阅者，进程才会退出。

基于逻辑复制状态监控流程（见 4.2.4.4），可以在 4.2.4.4.4 及时感知到故障恢复。

#### 4.2.4.4 监控流程

基于 4.2.3.3 识别的进程状态对自定义数据结构中元素的属性进行相关操作，以及相关数据的获取。

##### 4.2.4.4.1 进程启动

1. 设置进程id（pid）
2. 若进程处于故障状态（fault），则退出
3. 若进程处于关闭状态（disabled），则重置标记位（disabled=false）
4. 若进程处于等待故障检测状态（wait_abnormal_check），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）
5. 累加启动次数（start_count）
6. 若终止次数（start_count-1）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）

##### 4.2.4.4.2 进程重启

1. 设置进程id（pid）
2. 重置状态正常计数（normal_count=0）
3. 若进程处于故障状态（fault），则退出
4. 若进程处于关闭状态（disabled），则重置标记位（disabled=false）
5. 累加该relid的启动次数 start_count
6. 若**终止次数（start_count-1）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**

##### 4.2.4.4.3 进程终止

1. 设置进程id（pid）

2. 重置状态正常计数（normal_count=0）

3. 若为app进程（relid=NULL），则查询 pg_subscription 表中该订阅者状态（subenabled）

   3.1 **若（!subenabled），则报警，并设置标记位（disabled=true）。若进程当前状态正常（!fault），则清空状态计数（stateinfo）**

   3.2 若不满足3.1，则尝试与发布端通信。若通信失败，则累加通信异常计数（disconnect_count）；反之则累加进程故障计数（abnormal_count）。当**异常计数（disconnect_count或abnormal_count）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**，然后退出

   3.3 统计当前在运行的app进程（pid=有效值）数量，若小于配置项（max_replication_slots），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）；反之则更新为（wait_abnormal_check=true, abnormal_check=false）

4. 若为sync进程（relid=有效值），如果当前没有获取 pg_subscription_rel 表数据，则主动查询该订阅者所有数据

   4.1 **若该进程逻辑复制结束（srsubstate=='s'||srsubstate==‘r’），则更新标记位（finished=true** 
   **fault=false disabled=false），并清空状态计数（stateinfo）**

   4.2 若不满足4.1，则设置进程订阅表状态（relstate），依次进行3.1与3.2流程。

   4.3 若4.2未退出流程，则统计当前该订阅者名下未完成逻辑复制（srsubstate!='s'&&srsubstate!=‘r’）的订阅表数量。若小于等于配置项（max_sync_workers_per_subscription），则更新标记位（wait_abnormal_check=fasle, abnormal_check=true）；反之则更新为（wait_abnormal_check=true, abnormal_check=false）

##### 4.2.4.4.4 进程存活

1. 若进程处于故障检测阶段（abnormal_check）或者处于故障状态（fault），则累加状态正常计数（normal_count）
2. 若**正常计数（normal_count）超过故障恢复阈值，则认为故障已恢复。若进程处于故障状态（fault），则清除报警。重置标志位（fault=false abnormal_check=false wait_abnormal_check=false）**

##### 4.2.4.4.5 进程未启动

1. 若进程处于故障状态（fault），则退出
2. 若进程处于关闭状态（disabled），则退出
3. 若进程处于故障检测阶段（abnormal_check），则尝试与发布端通信。若通信失败，则累加通信异常计数（disconnect_count）；反之则累加进程故障计数（abnormal_count）。当**异常计数（disconnect_count或abnormal_count）超过故障阈值，则报警，并设置标记位（fault=true），重置标记位（abnormal_check=false wait_abnormal_check=false）**，然后退出
4. 若进程处于等待故障检测状态（wait_abnormal_check），则根据进程类型来选择执行 4.2.4.4.3 中3.3 或 4.3 流程

#### 4.2.4.5 监控进程重启

监控进程工作过程（见 4.2.4.4）中，会根据情况将相关异常信息（见 4.2.3.3）落盘。

PG进程重启后，监控进程重新启动。将从本地自定义表 citus_remove_shard_statue 中读取所有数据的属性（is_fault）。根据异常值作相应报警，提醒用户需自行确认是否存在相关故障。

